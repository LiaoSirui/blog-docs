## 集成学习（Ensemble Learning)

## Bagging

Bagging 是 bootstrap aggregating 的简写。先说一下 bootstrap，bootstrap 也称为自助法，它是一种有放回的抽样方法，目的为了得到统计量的分布以及置信区间。具体步骤如下

- 采用重抽样方法（有放回抽样）从原始样本中抽取一定数量的样本
- 根据抽出的样本计算想要得到的统计量 T
- 重复上述 N 次（一般大于 1000），得到 N 个统计量 T
- 根据这 N 个统计量，即可计算出统计量的置信区间

## Boosting

## Stacking

## 参考资料

- <https://mayuanucas.github.io/xgboost-lightgbm/#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0>

- <https://github.com/datawhalechina/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/machine-learning/Catboost.md>

- <https://itlubber.art/archives/lightgbm-lightgbm-catboost-analysis>

- <https://www.volcengine.com/theme/10820784-D-7-1>